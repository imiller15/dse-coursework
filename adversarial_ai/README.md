# CSC I4490: Adversarial AI

**The City College of New York**

**Instructor:** Dr. Allison Bishop, abishop@ccny.cuny.edu

## Course Description
This course will explore the nascent field of adversarial machine learning, which seeks to
understand and improve the behavior of machine learning algorithms in the presence of
adversarial interactions. It will cover some topics in the related fields of robust statistics (where
some of the training data is adversarially perturbed). In other words, we will interrogate each
step of a machine learning process, from the input data itself, to the training process, to the final
model performance and analyst queries, and ask: what happens if things go wrong? How might
we make choices that are less vulnerable to mistakes and manipulation?

## Course Objectives & Learning Outcomes
Students will learn how to systematically delineate threats to the integrity and performance of
machine learning models, and what kinds of approaches are being developed to address them.
Students will learn about several real examples of statistical models failing to behave as intended
in practice, and what can be done to anticipate and mitigate such issues. Students will also see
and work through several practical examples. By the end of the course, students will have
completed and evaluated a theoretical design for a machine learning application in terms of its
susceptibility to adversarial attack. (This project will be completed as a thought experiment in
several steps over the course of the semester.)

## Sample of Topics
1. What is machine learning/statistics/AI? How is it supposed to work in an ideal world?
2. Threat-modeling – what are the different ways that things can wrong in building and
using a statistical model?
3. Basic attacker strategies and examples
4. Some relevant foundations of statistics and probability theory
5. The assumptions underlying statistical significance and how they can be wrong in
practice
6. Robust statistics I – basic definitions and techniques for understanding and mitigating the
influence of outliers
7. Errors in machine learning classification models – examples and emerging theoretical
frameworks
8. Privacy leaks through analyst queries – examples and proposed mitigations
9. Robust statistics II – more advanced techniques for high dimensional data
10. The parable of “InstaHide” – an example of a real and broken system
11. Spam filters
12. Challenges of performing robust statistics in financial data